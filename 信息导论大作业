// An highlighted block
#读取数据并分类
def read_dataset():
    #读取数据
    data=pd.read_csv("C:/Users/liran/Desktop/glass.data",header=None)   data.columns=['Id','Rl','Na','Mg','Al','Si','K','Ca','Ba','Fe','Type']
    #删掉不需要的Id列
    data.drop(0,axis=1,inplace=True)
    #对数据进行去重处理
    data.drop_duplicates(inplace=True)
    #查看各个类别的玻璃各有多少条记录
    #print(data["Type"].value_counts())
    # 拆分数据集，划分为训练样本和验证样本
    # 提取出每个类别的数据
    t1 = data[data["Type"] == 1]
    t2 = data[data["Type"] == 2]
    t3 = data[data["Type"] == 3]
    t4 = data[data["Type"] == 4]
    t5 = data[data["Type"] == 5]
    t6 = data[data["Type"] == 6]
    t7 = data[data["Type"] == 7]
    # 对每个类别的数据进行洗牌 保证训练样本和测试样本取样方式相同
    t1 = t1.sample(len(t1), random_state=0)
    t2 = t2.sample(len(t2), random_state=0)
    t3 = t3.sample(len(t3), random_state=0)
    t4 = t4.sample(len(t4), random_state=0)
    t5 = t5.sample(len(t5), random_state=0)
    t6 = t6.sample(len(t6), random_state=0)
    t7 = t7.sample(len(t7), random_state=0)
    # 构建训练集和验证集
    #各自截取前70%，除最后列外的列，因为最后一列是y
    train_x=pd.concat([t1.iloc[:49,1:3],t2.iloc[:53,1:3],t3.iloc[:12, 1:3], t4.iloc[:0, 1:3], t5.iloc[:9, 1:3],t6.iloc[:6, 1:3], t7.iloc[:5, 1:3]], axis=0)
    train_y=pd.concat([t1.iloc[:49, -1], t2.iloc[:53, -1], t3.iloc[:12, -1], t4.iloc[:0, -1], t5.iloc[:9, -1],t6.iloc[:6, -1], t7.iloc[:5, -1]], axis=0)
    test_x=pd.concat([t1.iloc[49:,1:3],t2.iloc[53:, 1:3], t3.iloc[12:, 1:3], t4.iloc[0:, 1:3], t5.iloc[9:, 1:3],t6.iloc[6:, 1:3], t7.iloc[5:, 1:3]], axis=0)
    test_y = pd.concat([t1.iloc[49:, -1], t2.iloc[53:, -1], t3.iloc[12:, -1], t4.iloc[0:, -1], t5.iloc[9:, -1],t6.iloc[6:, -1], t7.iloc[5:, -1]], axis=0)
    return train_x,train_y,test_x,test_y,data
#KNN分类算法
class KNN:
    #初始化方法 k：邻居的个数
    def __init__(self, k):
        self.k = k
    #训练方法
    # X : [样本数量, 特征数量]，待训练的样本特征（属性）
    # y : [样本数量]，每个样本的目标值（标签）。
    def fit(self, X, y):
        # 将X转换成ndarray数组
        self.X = np.asarray(X)
        self.y = np.asarray(y)
    #根据参数传递的样本，对样本数据进行预测
    # X : [样本数量, 特征数量]，待训练的样本特征（属性）
    # return：数组类型，预测的结果
    def predict(self, X):
        X = np.asarray(X)
        result = []
        # 对ndarray数组进行遍历，每次取数组中的一行。
        for x in X:
          # 对于测试集中的每一个样本，依次与训练集中的所有样本求距离。
            dis = np.sqrt(np.sum((x - self.X) ** 2, axis=1))
          # 返回数组排序后，每个元素在原数组（排序之前的数组）中的索引。
            index = dis.argsort()
           # 进行截断，只取前k个元素。【取距离最近的k个元素的索引】
            index = index[:self.k]
         # 返回数组中每个元素出现的次数。元素必须是非负的整数。            count = np.bincount(self.y[index], weights=1 / dis[index])
            # 返回ndarray数组中，值最大的元素对应的索引。该索引就是我们判定的类别。# 最大元素索引，就是出现次数最多的元素。
            result.append(count.argmax())
        return np.asarray(result)
#绘图展示测试样本，每类数据点以不同的颜色显示
def vision_train(data_x,y):
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(1, 1, 1)  # 界面只需显示一个视图
    ax.set_title('KNN separable data_train set')  #视图名称
    plt.xlabel('RI-2')    #坐标轴名称
    plt.ylabel('Na-3')
    type1_x = []
    type1_y = []
    type2_x = []
    type2_y = []
    type3_x = []
    type3_y = []
    type4_x = []
    type4_y = []
    type5_x = []
    type5_y = []
    type6_x = []
    type6_y = []
    type7_x = []
    type7_y = []
    colors = ['r','g','b','y','k','m','c']   #定义显示的颜色
    #查找样本对应类型的索引
    for i in range(213):
        #防止list index out of range的错误，使用try except
        try:
            if (y[i] == 1):
                type1_x.append(data_x.iloc[i,0])
                type1_y.append(data_x.iloc[i,1])
            elif (y[i] == 2):
                type2_x.append(data_x.iloc[i, 0])
                type2_y.append(data_x.iloc[i, 1])
            elif (y[i] == 3):
                type3_x.append(data_x.iloc[i, 0])
                type3_y.append(data_x.iloc[i, 1])
            elif (y[i] == 4):
                type4_x.append(data_x.iloc[i, 0])
                type4_y.append(data_x.iloc[i, 1])
            elif (y[i] == 5):
                type5_x.append(data_x.iloc[i, 0])
                type5_y.append(data_x.iloc[i, 1])
            elif (y[i] == 6):
                type6_x.append(data_x.iloc[i, 0])
                type6_y.append(data_x.iloc[i, 1])
            else:
                type7_x.append(data_x.iloc[i, 0])
                type7_y.append(data_x.iloc[i, 1])
        except:
            continue
    ax.scatter(type1_x,type1_y,marker='o',color='r', label='building_windows_float_processed',s=10)
    ax.scatter(type2_x,type2_y,marker='o',color='g', label='building_windows_non_float_processed', s=10)
    ax.scatter(type3_x,type3_y,marker='o',color='b', label='vehicle_windows_float_processed', s=10)
    ax.scatter(type4_x,type4_y,marker='o',color='y', label='vehicle_windows_non_float_processed', s=10)
    ax.scatter(type5_x,type5_y,marker='o',color='k', label='containers', s=10)
    ax.scatter(type6_x,type6_y,marker='o',color='m', label='tableware', s=10)
    ax.scatter(type7_x,type7_y,marker='o',color='c', label='headlamps', s=10)
    plt.legend(loc = 'upper right')   #图例显示位置
    plt.show()
#验证样本可视化
def vision_test(test_x,test_y,result):
    right = test_x[result == test_y]
    wrong = test_x[result != test_y]
    fig = plt.figure(figsize=(10, 10))
    ax = fig.add_subplot(1, 1, 1)  # 界面只需显示一个视图
    ax.set_title('KNN separable data_test set')  # 视图名称
    plt.xlabel("RI-2")
    plt.ylabel("Na-3")
    ax.scatter(x=right.iloc[:, 0], y=right.iloc[:, 1], color='r', marker="x", label="right",s=10)
    ax.scatter(x=wrong.iloc[:, 0], y=wrong.iloc[:, 1], color="m", marker=">", label="wrong",s=10)
    plt.legend(loc="upper right")
    plt.show
# 归一化特征值  特征缩放
def autoNorm(dataSet):
    #求最大值和最小值
    #X_new=(x-min)/(max-min)
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    ranges = maxVals - minVals
    normDataSet = np.zeros(np.shape(dataSet))
    m = dataSet.shape[0]
    normDataSet = dataSet - np.tile(minVals, (m, 1))
    normDataSet = normDataSet / np.tile(ranges, (m, 1))
    return normDataSet, ranges, minVals
def main():
    #读取数据
    train_x,train_y,test_x,test_y,data = read_dataset()
    # 创建KNN对象，进行训练和验证
    knn = KNN(k=17)
    # 进行训练
    knn.fit(train_x, train_y)
    # 进行验证
    result = knn.predict(test_x)
    #输出测试正确个数及正确率
    print(sum(result == test_y))
    print(sum(result == test_y)/len(result))
    #pandas读取的数据要转换成list之后再进行查找索引操作
    trainy = train_y.values.tolist()
    #进行可视化
    #训练样本可视化
    #vision_train(train_x,trainy)
    #测试样本可视化
    #vision_test(test_x,test_y,result)
    #归一化处理数据
    data_x,ranges,minVals=autoNorm(train_x)
    knn1 = KNN(k=17)
    knn1.fit(data_x,train_y)
    result = knn1.predict(test_x)
    # 输出测试正确个数及正确率
    print(sum(result == test_y))
    print(sum(result == test_y) / len(result))
    #归一化后的可视化
vision_train(data_x,trainy)

if __name__ == '__main__':
    main()
